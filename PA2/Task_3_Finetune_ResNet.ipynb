{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task 3 - Finetune ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X4X2hmaEmip"
      },
      "source": [
        "# Task 3: Finetune ResNet\n",
        "# CENG501 - Spring 2021 - PA2 - Berker AcÄ±r - 2098697\n",
        "\n",
        "In this task, we will practice transfer learning by adapting and finetuning ResNet18 (pretrained on ImageNet) for CIFAR10.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRaKrjO5JSu-"
      },
      "source": [
        "## 1 Import the Modules\n",
        "\n",
        "Let us start with importing some libraries that we will use throughout the task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4L5nogMKyNx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c60952bd-cb72-4f58-9aa8-ac43be2763cc"
      },
      "source": [
        "import matplotlib.pyplot as plt # For plotting\n",
        "import numpy as np              # NumPy, for working with arrays/tensors \n",
        "import time                     # For measuring time\n",
        "import random                   # Python's random library\n",
        "\n",
        "# PyTorch libraries:\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# install and import the torchinfo library\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = [12, 8]\n",
        "plt.rcParams['figure.dpi'] = 100 # 200 e.g. is really fine, but slower"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/d3/11f9901d75f4d105b2b1700c81f83579fd33c4cf0ec88bb7a165d96c7bb4/torchinfo-0.1.5-py3-none-any.whl\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-0.1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BXVQOGRI4Sc"
      },
      "source": [
        "### 1.1 Enable GPU\n",
        "\n",
        "From \"Edit -> Notebook Settings -> Hardware accelerator\" select GPU. With the following we will specify to PyTorch that we want to use the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97DJEyArJLcR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98408945-8922-416e-9ae3-a5d962f2824f"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  print(\"Cuda (GPU support) is available and enabled!\")\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  print(\"Cuda (GPU support) is not available :(\")\n",
        "  device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda (GPU support) is available and enabled!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KyHtEWkOuZW"
      },
      "source": [
        "## 2 Download and Test Pretrained ResNet18\n",
        "\n",
        "We have talked about ResNet in detail in the lectures. We will take Pytorch's ResNet18 model (https://pytorch.org/hub/pytorch_vision_resnet/), which was trained on ImageNet, and adapt&finetune it for CIFAR10.\n",
        "\n",
        "Here is a couple of critical information about ResNet18's input (from Pytorch document):\n",
        "\n",
        "\"All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225].\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWxyCVI_OTdi"
      },
      "source": [
        "### 2.1 Download ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwOkHvOqOuyb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "aa5f4e99-948a-4ea4-d302-463dd347c307"
      },
      "source": [
        "# Thanks to Pytorch datasets, this is very easy:\n",
        "\n",
        "OrigResNet18 = None\n",
        "###########################################################\n",
        "# @TODO: Look at PyTorch's documentation for downloading  #\n",
        "# and loading a pretrained ResNet18 model.                #\n",
        "#                                                         #\n",
        "# Hint: This should be a single function call.            #\n",
        "###########################################################\n",
        "OrigResNet18 = torch.hub.load('pytorch/vision:v0.9.0', 'resnet18', pretrained=True)\n",
        "###########################################################\n",
        "#                         END OF YOUR CODE                #\n",
        "###########################################################\n",
        "print(OrigResNet18)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c5febab9c9d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Hint: This should be a single function call.            #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m###########################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mOrigResNet18\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pytorch/vision:v0.9.0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'resnet18'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m###########################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#                         END OF YOUR CODE                #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(repo_or_dir, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msource\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'github'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mrepo_or_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_cache_or_reload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_or_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_reload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_or_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36m_get_cache_or_reload\u001b[0;34m(github, force_reload, verbose)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# Validate the tag/branch is from the original repo instead of a forked repo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0m_validate_not_a_forked_repo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_owner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mcached_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhub_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_br\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36m_validate_not_a_forked_repo\u001b[0;34m(repo_owner, repo_name, branch)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'?per_page=100&page='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_content_charset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: rate limit exceeded"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bDj9IQRL7ms"
      },
      "source": [
        "### 2.2 Get ImageNet Labels\n",
        "\n",
        "Before we finetune ResNet18, let us see what it predicts on CIFAR10. To be able to do so, we will require the list of ImageNet labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwRoWkU0L_Cp"
      },
      "source": [
        "# Download ImageNet labels\n",
        "!wget -nc https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
        "\n",
        "# Read the categories\n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk6K0jC_OZs0"
      },
      "source": [
        "### 2.3 Load CIFAR10\n",
        "\n",
        "As we mentioned above, ResNet18 expects images with resolution 224x224 and normalized with a mean & std. Therefore, while loading CIFAR10, we will apply certain transformations to handle these requirements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Udg6NjvPU4a"
      },
      "source": [
        "batch_size = 8\n",
        "\n",
        "TF = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=TF)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=TF)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "CIFAR10_classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUxUQKZSO3q2"
      },
      "source": [
        "### 2.4 Apply Pre-trained ResNet18 on CIFAR10\n",
        "\n",
        "Let us look at what ResNet18 predicts on a batch of CIFAR10. For a set of samples, we will visualize the images and look at ResNet18's top predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A19MMClxQIyr"
      },
      "source": [
        "# Get a batch\n",
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Get scores for classes on the batch\n",
        "with torch.no_grad():\n",
        "    output = OrigResNet18(images)\n",
        "\n",
        "# Convert them to probabilities (shape: batch_size x 1000)\n",
        "probabilities = torch.nn.functional.softmax(output, dim=1)\n",
        "\n",
        "# Show results on a 2x2 grid\n",
        "S=2\n",
        "for i in range(S):\n",
        "  for j in range(S):\n",
        "    X = images[i*S+j]\n",
        "    X = np.transpose((X.numpy()/2+0.5), (1, 2, 0))\n",
        "    top1_prob, top1_catid = torch.topk(probabilities[i*S+j], 1)\n",
        "    title = \"{} p:{:1.2f}\".format(categories[top1_catid], top1_prob.item())\n",
        "\n",
        "    plt.subplot(S, S, i*S+j+1)\n",
        "    plt.imshow(X)\n",
        "    plt.axis('off')\n",
        "    plt.title(title)\n",
        "    plt.subplots_adjust(hspace = 0.5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHmjt73oP3f9"
      },
      "source": [
        "We see that the predictions are way off and we will hopefully get better results with some finetuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV9omiSefxOU"
      },
      "source": [
        "## 3 Adapt ResNet18 for CIFAR10\n",
        "\n",
        "We will freeze the parameters of ResNet18 and replace the last layer of ResNet18 with a new layer which we will finetune."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaL7AMbzZqTw"
      },
      "source": [
        "# Copy ResNet18\n",
        "import copy \n",
        "NewResNet18 = copy.deepcopy(OrigResNet18)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTt3F-EHI1_9"
      },
      "source": [
        "### 3.1 Freeze Parameters of ResNet18\n",
        "\n",
        "Before doing so, we \"freeze\" the earlier layers but setting their `requires_grad` parameter to `False`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42z_IRpzINbe"
      },
      "source": [
        "###########################################################\n",
        "# @TODO: Go over the parameters of NewResNet18 and set    #\n",
        "# requires_grad for all parameters to False.              #\n",
        "#                                                         #\n",
        "# Hint: Check parameters() member function of NewResNet18.#\n",
        "###########################################################\n",
        "print(NewResNet18.parameters)\n",
        "for param in NewResNet18.parameters():\n",
        "  param.requires_grad = False\n",
        "###########################################################\n",
        "#                         END OF YOUR CODE                #\n",
        "###########################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htbhG_H5I53Z"
      },
      "source": [
        "### 3.2 Add a New Learnable FC Layer to ResNet18\n",
        "\n",
        "If you look at the summary of ResNet18 shown above, you will see that the last layer is:\n",
        "\n",
        "  `(fc): Linear(in_features=512, out_features=1000, bias=True)`\n",
        "\n",
        "In our case, we should just replace this with a new FC layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh70CY4gJuiH"
      },
      "source": [
        "NewResNet18.fc = None\n",
        "###########################################################\n",
        "# @TODO: Create a new layer and save it into              #\n",
        "# NewResNet18.fc. This new layer will map the activations #\n",
        "# of the previous layer to the outputs for the CIFAR10    #\n",
        "# classes.                                                #\n",
        "###########################################################\n",
        "NewResNet18.fc = nn.Linear(512, 10)\n",
        "###########################################################\n",
        "#                         END OF YOUR CODE                #\n",
        "###########################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQic000dKCBi"
      },
      "source": [
        "### 3.3 Visualize the Model\n",
        "\n",
        "Now, let us see whether the new fc layer is correct for CIFAR10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9opKZmXSKKNV"
      },
      "source": [
        "print(NewResNet18.fc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8VqkhyAf1s4"
      },
      "source": [
        "## 4 Finetune ResNet18\n",
        "\n",
        "While finetuning ResNet18, we will just update the last layer. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6Xwis1-J26R"
      },
      "source": [
        "### 4.1 Training Method\n",
        "\n",
        "This is the same training method from Task 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEZU8jZpJ5At"
      },
      "source": [
        "def train(model, criterion, optimizer, epochs, dataloader, verbose=True):\n",
        "  \"\"\"\n",
        "    Define the trainer function. We can use this for training any model.\n",
        "    The parameter names are self-explanatory.\n",
        "\n",
        "    Returns: the loss history.\n",
        "  \"\"\"\n",
        "  loss_history = [] \n",
        "  for epoch in range(epochs):\n",
        "    for i, data in enumerate(dataloader, 0):    \n",
        "      \n",
        "      # Our batch:\n",
        "      inputs, labels = data\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # zero the gradients as PyTorch accumulates them\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Obtain the scores\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      # Calculate loss\n",
        "      loss = criterion(outputs.to(device), labels)\n",
        "\n",
        "      # Backpropagate\n",
        "      loss.backward()\n",
        "\n",
        "      # Update the weights\n",
        "      optimizer.step()\n",
        "\n",
        "      loss_history.append(loss.item())\n",
        "    \n",
        "    if verbose: print(f'Epoch {epoch} / {epochs}: avg. loss of last 5 iterations {np.sum(loss_history[:-6:-1])/5}')\n",
        "\n",
        "  return loss_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15VCbg0lKPIz"
      },
      "source": [
        "### 4.2 Finetune the Adapted ResNet18 on CIFAR10\n",
        "\n",
        "We will only provide the learnable parameters to the optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfeLlbI4KU_M"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# For reproducibility, let us recreate the FC layer here with a fixed seed:\n",
        "torch.manual_seed(501)\n",
        "random.seed(501)\n",
        "np.random.seed(501)    \n",
        "\n",
        "NewResNet18.fc = None\n",
        "###########################################################\n",
        "# @TODO: Repeat what you did 3.2 here                     #\n",
        "###########################################################\n",
        "NewResNet18.fc = nn.Linear(512, 10)\n",
        "###########################################################\n",
        "#                         END OF YOUR CODE                #\n",
        "###########################################################\n",
        "\n",
        "def get_learnable_parameters(model):\n",
        "    params_to_update = []\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "    return params_to_update\n",
        "\n",
        "parameters_to_update = get_learnable_parameters(NewResNet18)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(parameters_to_update, lr=0.0001, momentum=0.95)\n",
        "\n",
        "NewResNet18 = NewResNet18.to(device)\n",
        "epochs = 2\n",
        "loss_history = train(NewResNet18, criterion, optimizer, epochs, trainloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SUT6gj9KenX"
      },
      "source": [
        "### 4.3 The Loss Curve\n",
        "\n",
        "You will see that the loss curve is very noisy, which suggests that we should finetune our hyper-parameters. Though, we will see that we get already reasonably well performance on test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNzegVoFKgXu"
      },
      "source": [
        "plt.plot(loss_history)\n",
        "plt.xlabel('Iteration number')\n",
        "plt.ylabel('Loss value')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cBp7Xu_Kkhp"
      },
      "source": [
        "### 4.4 Quantitative Results\n",
        "\n",
        "We can analyze the accuracy of the predictions as follows. You should see around 69\\% accuracies. We can finetune the hyperparameters to obtain better results. But we will skip that and go for a bigger model.\n",
        "\n",
        "*Disclaimer: This code piece is taken from PyTorch examples.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz0pvi8AKmse"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "NewResNet18 = NewResNet18.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = NewResNet18(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69QV-5JKVHVl"
      },
      "source": [
        "### 4.5 Visual Results\n",
        "\n",
        "We see that with just two epochs of training a single FC layer, we can get decent results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ALpDTyfVNJd"
      },
      "source": [
        "# Get a batch\n",
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "images = images.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "# Get scores for classes on the batch\n",
        "with torch.no_grad():\n",
        "    output = NewResNet18(images)\n",
        "\n",
        "# Convert them to probabilities (shape: batch_size x 1000)\n",
        "probabilities = torch.nn.functional.softmax(output, dim=1)\n",
        "\n",
        "# Show results on a 2x2 grid\n",
        "S=2\n",
        "for i in range(S):\n",
        "  for j in range(S):\n",
        "    X = images[i*S+j]\n",
        "    X = np.transpose((X.to(\"cpu\").numpy()/2+0.5), (1, 2, 0))\n",
        "    top1_prob, top1_catid = torch.topk(probabilities[i*S+j], 1)\n",
        "    title = \"{} p:{:1.2f}\".format(CIFAR10_classes[top1_catid], top1_prob.item())\n",
        "\n",
        "    plt.subplot(S, S, i*S+j+1)\n",
        "    plt.imshow(X)\n",
        "    plt.axis('off')\n",
        "    plt.title(title)\n",
        "    plt.subplots_adjust(hspace = 0.5)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}